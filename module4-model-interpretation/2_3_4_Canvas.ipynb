{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-3-4-Canvas.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJOPOErvc90MhNEyoTCtr0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/austinlasseter/DS-Unit-2-Applied-Modeling/blob/master/module4-model-interpretation/2_3_4_Canvas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIVjc4B-e62K"
      },
      "source": [
        "# 1. visualize and interpret partial dependence plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-_Kk9ZOeT1z"
      },
      "source": [
        "## Overview\n",
        "In this sprint, and the unit overall, we have been focusing on the feature importance as determined by simply ranking them. We've looked at lists of features and their contribution to the model. But sometimes, we want more information about how the model is working and how a specific feature(s) affects the model predictions. One of the main way to take a look inside a \"black box\" model is to utilize partial dependence plots.\n",
        "\n",
        "A partial dependence plot can be used to show how a model prediction partially depends on values of the input variables of interest (the input feature). For example, in the data we'll explore below, we can fit a model to predict wine quality. Once we have the model fit, we can isolate a particular feature and visualize how the model prediction depends on that feature over its range of values. The plots below will show how we visualize the model prediction's dependence on alcohol content.\n",
        "\n",
        "## Follow Along\n",
        "We're back to the wine quality data set. In this example, we're going to change our target to having only two classes (bad/good): 0 for quality less than or equal to 5 and 1 for above five. Rethinking this problem as a binary classification will make it easier to visualize our partial dependence plots because the model itself will be simpler.\n",
        "\n",
        "After loading in the data, we'll fir a simple decision tree classifier model. We're not going to split the data into training and testing sets because we're not looking at the accuracy or other evaluation metrics right now. So we'll use all of the data to train the model and to create the partial dependence plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMX5mS8FeWFs"
      },
      "source": [
        "# Load the dataset\n",
        "import pandas as pd\n",
        "wine = pd.read_csv('winequality-red.csv', sep=';')\n",
        "wine.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDmq6rZPebMU"
      },
      "source": [
        "# Set the features list and target variable \n",
        "target = 'quality'\n",
        "X = wine.drop(target, axis=1)\n",
        "\n",
        "# Create the target array\n",
        "y = wine['quality']\n",
        "\n",
        "# Map the target to a binary class at quality = 5\n",
        "y = y.apply(lambda x: 0 if x <= 5 else 1)\n",
        "\n",
        "# Instantiate the classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "wine_model = clf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8uXi_JZedcH"
      },
      "source": [
        "## Calculating the Partial Dependence\n",
        "We always calculate our partial dependence values after we have fit a model. Using the plot_partial_dependence() module, we specify the features that we would like to visualize. In this case, the alcohol and chlorides are the two features we're using. Usually, you would have analyzed the feature importances and then selected the most important features. In this case, we're using a slightly different red wine data set than what is available from the scikit-learn datasets module, but alcohol is one of the top features in importance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0icugARyeecn",
        "outputId": "d8ab7c37-f9f4-43fc-e102-ada4d0ada1fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "source": [
        "from sklearn.inspection import plot_partial_dependence\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(1,1, figsize=(12,4))\n",
        "plot_partial_dependence(wine_model, feature_names=X.columns, \n",
        "                        features=['alcohol','chlorides'], \n",
        "                        X=X, grid_resolution=50, ax=ax);\n",
        "\n",
        "ax.set_title('Wine: Partial Dependence')\n",
        "\n",
        "#plt.show()\n",
        "\n",
        "plt.clf()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3780e93d2850>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m plot_partial_dependence(wine_model, feature_names=X.columns, \n\u001b[0m\u001b[1;32m      6\u001b[0m                         \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alcohol'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'chlorides'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                         X=X, grid_resolution=50, ax=ax);\n",
            "\u001b[0;31mNameError\u001b[0m: name 'wine_model' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrWSrrQ3eild"
      },
      "source": [
        "On the left plot, we can see as the percentage of alcohol increases, the model more strongly predicts higher quality. On the right, the amount of chlorides in the wine doesn't seem to affect the prediction as much as the alcohol content feature.\n",
        "\n",
        "Now, we're going to use a different library to visualize the partial dependence for one feature. This plot is calculating the same dependence of the feature but is plotting all of the predictions (shaded area) as well as the average (solid line)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LFm51XXegSl"
      },
      "source": [
        "from pdpbox.pdp import pdp_isolate, pdp_plot\n",
        "\n",
        "# Create the plot for a single feature isolated\n",
        "\n",
        "isolated = pdp_isolate(\n",
        "    model= wine_model,\n",
        "    dataset=X,\n",
        "    model_features=X.columns,\n",
        "    feature='alcohol'\n",
        ")\n",
        "\n",
        "pdp_plot(isolated, feature_name='Alcohol');\n",
        "\n",
        "plt.clf()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5teSCgKeodO"
      },
      "source": [
        "# 2. explain individual predictions with shapley value plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ai0qxT-ethH"
      },
      "source": [
        "## Overview\n",
        "In this objective, we'll dive a little deeper into how individual features contribute to making a prediction. A quantity called a Shapley value borrows from game theory concepts to try to explain the difference between the prediction of an individual observation compared to the average prediction from all the observations (instances).\n",
        "\n",
        "One way to consider this problem is to think of the features in the model working together to make a prediction. For example, using the wine data set from the previous objective, we can consider the alcohol content, the sulphates, and the pH. For one observation (row of the DataFrame), they work together to make a prediction. The rest of the rows all work together to make the average prediction. The Shapley values look at each feature's contribution to the single row prediction and explain exactly how it make it different from the average prediction.\n",
        "\n",
        "Let' work through an example using the SHAP library which stands for SHapley Additive exPlanations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaKdzsdFerMh"
      },
      "source": [
        "# Load the dataset\n",
        "import pandas as pd\n",
        "wine = pd.read_csv('winequality-red.csv', sep=';')\n",
        "wine.head()\n",
        "\n",
        "# Set the features list and target variable \n",
        "target = 'quality'\n",
        "X = wine.drop(target, axis=1)\n",
        "\n",
        "# Create the target array\n",
        "y = wine['quality']\n",
        "\n",
        "# Map the target to a binary class at quality = 5\n",
        "y = y.apply(lambda x: 0 if x <= 5 else 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSoRoPrJexdh"
      },
      "source": [
        "To calculate the Shapley values, we'll be fitting a xgboost classifier model to the data. The TreeExplainer() is used to explain the output of ensemble tree models. From the explainer values, we calculate the Shapley values and then visualize the results for a single observation (instance)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM9YH-v9exzJ"
      },
      "source": [
        "# Import shap\n",
        "import shap\n",
        "\n",
        "# Instantiate and fit the model\n",
        "from xgboost import XGBClassifier\n",
        "xgb = XGBClassifier(random_state=42)\n",
        "wine_model = xgb.fit(X, y)\n",
        "mybooster = wine_model.get_booster()\n",
        "\n",
        "# The following code correction for an encoding error\n",
        "model_bytearray = mybooster.save_raw()[4:]\n",
        "def myfun(self=None):\n",
        "    return model_bytearray\n",
        "mybooster.save_raw = myfun\n",
        "\n",
        "# Shap explainer initilization\n",
        "shap_ex = shap.TreeExplainer(mybooster)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJEtzrpYe0-k"
      },
      "source": [
        "\n",
        "# Calculate the shapley values\n",
        "shap_values = shap_ex.shap_values(X)\n",
        "\n",
        "# Initialize the plot\n",
        "shap.initjs()\n",
        "\n",
        "# Plot the values for the 25th row of the \n",
        "shap.force_plot(shap_ex.expected_value, shap_values[25,:], X.iloc[25,:])\n",
        "\n",
        "plt.clf()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3epula5me2ow"
      },
      "source": [
        "We can interpret the above plot in the following way: the value for volatile acidity was more important in predicting wine quality. The alcohol content and residual sugar (and others) were less important in predicting the wine quality.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZXkJiX6e25Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}