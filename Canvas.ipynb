{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Canvas.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMO5HJAdUNKqW8bSD7eCOkA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/austinlasseter/DS-Unit-2-Applied-Modeling/blob/master/Canvas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V7c5VBGcUxf"
      },
      "source": [
        "# Objective 1 - get permutation importances for model interpretation and feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRrCiE8kYj3l"
      },
      "source": [
        "In many of the models we've fit, we've looked at the feature importance. This has been accomplished by simply ranking the features after fitting the model. In addition to these basic methods, we can also look at what happens when we change a specific feature. This is called the permutation importance.\n",
        "\n",
        "The permute something means to change the order. When we fit a model, we measure the accuracy by comparing our model predictions to the test or validation data. We can test the importance of a feature by permuting the values and then calculating the accuracy against the test set.\n",
        "\n",
        "The process works something like this:\n",
        "\n",
        "    Fit a model and calculate the accuracy\n",
        "    Choose a feature (either by rank the importance or some other method) and randomly permute the values for just that feat\n",
        "    Calculate the accuracy again with the permuted column\n",
        "    A decrease in accuracy: that feature is important to the model\n",
        "    Accuracy that stays the same: the feature isn't important to the model and could be replaced by random numbers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yleQZS0YmOl"
      },
      "source": [
        "\n",
        "We'll use the Australian weather data set from the previous module and permute or randomize a few of the features in the test set. The accuracy should change, decrease, for features that are important to the model. The accuracy should remain essentially the same for features that are not very important to the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrhvcCtOY8s8",
        "outputId": "36102aca-ae3b-4e03-af5f-4d75425eec88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "!wget https://rattle.togaware.com/weatherAUS.csv\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-06 00:57:36--  https://rattle.togaware.com/weatherAUS.csv\n",
            "Resolving rattle.togaware.com (rattle.togaware.com)... 207.38.86.6, 2605:de00:1:1:4a:2:0:e5\n",
            "Connecting to rattle.togaware.com (rattle.togaware.com)|207.38.86.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19780788 (19M) [text/csv]\n",
            "Saving to: ‘weatherAUS.csv’\n",
            "\n",
            "weatherAUS.csv      100%[===================>]  18.86M  8.90MB/s    in 2.1s    \n",
            "\n",
            "2020-10-06 00:57:39 (8.90 MB/s) - ‘weatherAUS.csv’ saved [19780788/19780788]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTsBYEsXYosU",
        "outputId": "ed194ae4-2cbc-459f-80ed-4491924e111d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "# Import libraries, load data, and view\n",
        "import pandas as pd\n",
        "weather = pd.read_csv('weatherAUS.csv')\n",
        "weather.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Location</th>\n",
              "      <th>MinTemp</th>\n",
              "      <th>MaxTemp</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Evaporation</th>\n",
              "      <th>Sunshine</th>\n",
              "      <th>WindGustDir</th>\n",
              "      <th>WindGustSpeed</th>\n",
              "      <th>WindDir9am</th>\n",
              "      <th>WindDir3pm</th>\n",
              "      <th>WindSpeed9am</th>\n",
              "      <th>WindSpeed3pm</th>\n",
              "      <th>Humidity9am</th>\n",
              "      <th>Humidity3pm</th>\n",
              "      <th>Pressure9am</th>\n",
              "      <th>Pressure3pm</th>\n",
              "      <th>Cloud9am</th>\n",
              "      <th>Cloud3pm</th>\n",
              "      <th>Temp9am</th>\n",
              "      <th>Temp3pm</th>\n",
              "      <th>RainToday</th>\n",
              "      <th>RISK_MM</th>\n",
              "      <th>RainTomorrow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008-12-01</td>\n",
              "      <td>Albury</td>\n",
              "      <td>13.4</td>\n",
              "      <td>22.9</td>\n",
              "      <td>0.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>W</td>\n",
              "      <td>44.0</td>\n",
              "      <td>W</td>\n",
              "      <td>WNW</td>\n",
              "      <td>20.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1007.7</td>\n",
              "      <td>1007.1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.9</td>\n",
              "      <td>21.8</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2008-12-02</td>\n",
              "      <td>Albury</td>\n",
              "      <td>7.4</td>\n",
              "      <td>25.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WNW</td>\n",
              "      <td>44.0</td>\n",
              "      <td>NNW</td>\n",
              "      <td>WSW</td>\n",
              "      <td>4.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1010.6</td>\n",
              "      <td>1007.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.2</td>\n",
              "      <td>24.3</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2008-12-03</td>\n",
              "      <td>Albury</td>\n",
              "      <td>12.9</td>\n",
              "      <td>25.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WSW</td>\n",
              "      <td>46.0</td>\n",
              "      <td>W</td>\n",
              "      <td>WSW</td>\n",
              "      <td>19.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.6</td>\n",
              "      <td>1008.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>23.2</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2008-12-04</td>\n",
              "      <td>Albury</td>\n",
              "      <td>9.2</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NE</td>\n",
              "      <td>24.0</td>\n",
              "      <td>SE</td>\n",
              "      <td>E</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1017.6</td>\n",
              "      <td>1012.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.1</td>\n",
              "      <td>26.5</td>\n",
              "      <td>No</td>\n",
              "      <td>1.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2008-12-05</td>\n",
              "      <td>Albury</td>\n",
              "      <td>17.5</td>\n",
              "      <td>32.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>W</td>\n",
              "      <td>41.0</td>\n",
              "      <td>ENE</td>\n",
              "      <td>NW</td>\n",
              "      <td>7.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1010.8</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>29.7</td>\n",
              "      <td>No</td>\n",
              "      <td>0.2</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date Location  MinTemp  ...  RainToday  RISK_MM  RainTomorrow\n",
              "0  2008-12-01   Albury     13.4  ...         No      0.0            No\n",
              "1  2008-12-02   Albury      7.4  ...         No      0.0            No\n",
              "2  2008-12-03   Albury     12.9  ...         No      0.0            No\n",
              "3  2008-12-04   Albury      9.2  ...         No      1.0            No\n",
              "4  2008-12-05   Albury     17.5  ...         No      0.2            No\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67gQ59heYt4t"
      },
      "source": [
        "\n",
        "# Drop columns with high-percentage of missing values\n",
        "cols_drop = ['Location', 'Evaporation', 'Sunshine', 'Cloud9am', 'Cloud3pm', 'RISK_MM']\n",
        "weather_drop = weather.drop(cols_drop, axis=1)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-IW4zMEanmz"
      },
      "source": [
        "# Convert the 'Date' column to datetime, extract month\n",
        "weather_drop['Date'] = pd.to_datetime(weather_drop['Date'], infer_datetime_format=True).dt.month"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAwGZY5Aau5I"
      },
      "source": [
        "## Create Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGaAjGefaoK6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "numeric_features = ['MinTemp', 'MaxTemp', 'Rainfall', 'WindGustSpeed', \n",
        "                    'WindSpeed9am','WindSpeed3pm', 'Humidity9am', \n",
        "                    'Humidity3pm', 'Pressure9am','Pressure3pm', \n",
        "                    'Temp9am', 'Temp3pm']\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = ['WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday']\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('ordinal', OrdinalEncoder())])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "\n",
        "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                  ('classifier', DecisionTreeClassifier())])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ny5GhIsa0G0"
      },
      "source": [
        "## Train and Fit the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWlbvSRIa0rZ"
      },
      "source": [
        "# Create the feature matrix \n",
        "X = weather_drop.drop('RainTomorrow', axis=1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1tTByYfbIBl",
        "outputId": "5bb44c30-66f4-4dcc-9a2d-e8cbd7a53c04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "weather['RainTomorrow'].value_counts()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "No     136485\n",
              "Yes     37405\n",
              "Name: RainTomorrow, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU1RJjKqbDK2",
        "outputId": "ffb74180-e742-44c0-8363-273ce38c0bd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Create and encode the target array\n",
        "\n",
        "weather['RainT']=np.where(weather['RainTomorrow']==\"Yes\", 1, 0)\n",
        "print(weather['RainT'].value_counts())\n",
        "y = weather['RainT']"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    140861\n",
            "1     37405\n",
            "Name: RainT, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxcSAlYDa4Fs",
        "outputId": "c205f1af-c15a-4acc-b218-a1180237d71c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import the train_test_split utility\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create the training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "clf.fit(X_train,y_train)\n",
        "print('Validation Accuracy', clf.score(X_test, y_test))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7865316654512817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpYghNMbb9uj"
      },
      "source": [
        "## Feature Importances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDI2bqjUb5SH",
        "outputId": "e5b74063-52d3-407a-96cf-aae4321569e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Features (order in which they were preprocessed)\n",
        "features_order = numeric_features + categorical_features\n",
        "\n",
        "importances = pd.Series(clf.steps[1][1].feature_importances_, features_order)\n",
        "\n",
        "# Plot feature importances\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(10,n/2))\n",
        "plt.title(f'Top {n} features')\n",
        "importances.sort_values()[-n:].plot.barh(color='grey')\n",
        "\n",
        "plt.clf()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVeJbEAocAeA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZXy_8bCcC-f"
      },
      "source": [
        "We can now try a few of the columns and see how permutation of their values affects the accuracy. We'll start with the most important feature (Humidity3pm) and then do the same with one of the less important features (WindSpeed3pm).\n",
        "\n",
        "We do need to remember to preprocess the data in the same way we did inside of the pipeline. For the numeric features, we used the SimpleImputer() and the StandardScaler."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXgymfPFcDZk",
        "outputId": "21f1482c-253b-4993-dc6a-9a3e76a0f2eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Permute the values in the more important column\n",
        "feature = 'Humidity3pm'\n",
        "\n",
        "X_test_permuted = X_test.copy()\n",
        "\n",
        "# Fill in missing values\n",
        "X_test_permuted[feature].fillna(value = X_test_permuted[feature].median(), inplace=True)\n",
        "\n",
        "# Permute\n",
        "X_test_permuted[feature] = np.random.permutation(X_test[feature])\n",
        "\n",
        "print('Feature permuted: ', feature)\n",
        "print('Validation Accuracy', clf.score(X_test, y_test))\n",
        "print('Validation Accuracy (permuted)', clf.score(X_test_permuted, y_test))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature permuted:  Humidity3pm\n",
            "Validation Accuracy 0.7865316654512817\n",
            "Validation Accuracy (permuted) 0.7025298704212711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jErU6QyocFeD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1thNtaKcHsk"
      },
      "source": [
        "The accuracy went down, as we would expect. So Humidity3pm has some affect on the model. Let's try another feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRoH63bkcH-V",
        "outputId": "403f351f-a635-44cf-ea19-4e8c5628f48b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Permute the values in a less important column\n",
        "feature = 'WindSpeed3pm'\n",
        "\n",
        "X_test_permuted = X_test.copy()\n",
        "\n",
        "# Fill in missing values\n",
        "X_test_permuted[feature].fillna(value = X_test_permuted[feature].median(), inplace=True)\n",
        "\n",
        "# Permute\n",
        "X_test_permuted[feature] = np.random.permutation(X_test[feature])\n",
        "\n",
        "print('Feature permuted: ', feature)\n",
        "print('Validation Accuracy', clf.score(X_test, y_test))\n",
        "print('Validation Accuracy (permuted)', clf.score(X_test_permuted, y_test))\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature permuted:  WindSpeed3pm\n",
            "Validation Accuracy 0.7865316654512817\n",
            "Validation Accuracy (permuted) 0.7743030235036742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYWtzVfNcMAm"
      },
      "source": [
        "The decrease in accuracy was not nearly as significant, so WindSpeed3pm is not as important to the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxp8CX_wcT0s"
      },
      "source": [
        "# Objective 2 - use xgboost for gradient boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ny0h8k_ccM9"
      },
      "source": [
        "## Bagging\n",
        "\n",
        "In the previous unit, we used the random forest ensemble method, where the ensemble was a collection of trees. An ensemble method makes use of bootstrap sampling where random samples are drawn from the training set with replacement. A decision tree is trained on each sample and each tree gets a \"vote\" for the class. The class with the most votes wins. This process is called bootstrap aggregating or bagging.\n",
        "## Boosting\n",
        "\n",
        "One of the other important processes in machine learning is boosting. For our example, we'll start by training our data set with a weak learner which is often a decision tree with one node or split (called a stump). We find the data that was misclassified and start the next round by assigning them a larger weight. We continue to train decision tree stumps and add larger weight to the mistakes for each model. The samples that are difficult to classify will receive increasing larger weights and eventually be correctly classified. This process is called adaptive boosting and is the source of the AdaBoost() name.\n",
        "## Gradient Boosting\n",
        "\n",
        "Gradient boosting is another boosting technique that makes use of a gradient descent method when adding trees to the model. When a tree is added, the hyperparameters are adjusted to minimize the loss function following the negative gradient. THe popular XGBoot algorithm makes use of this process.\n",
        "\n",
        "In the next section, we'll implement the two boosting methods described above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAPi_WyNcJzp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aX2-meIcnLe"
      },
      "source": [
        "First, we'll use the AdaBoost classifier in scikit-learn and then compare that to the results from the XGBoost scikit-learn API. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpq9DXadcnaO",
        "outputId": "5c52cd3c-2d9b-402d-e136-c5d24044fb14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load in libraries, data\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create X, y and training/test sets\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.4, random_state=42)\n",
        "\n",
        "# Import the classifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_classifier = AdaBoostClassifier(n_estimators=50, learning_rate=1.5, random_state=42)\n",
        "ada_classifier.fit(X_train,y_train)\n",
        "\n",
        "print('Validation Accuracy: Adaboost', ada_classifier.score(X_test, y_test))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: Adaboost 0.9666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkTm2ExCcqw1"
      },
      "source": [
        "The classifier performed very well, but this data set is intended to be easy to classify. We set the train-test split at 60/40 so the classifier was \"challenged\" a little more with a smaller training set.\n",
        "\n",
        "Now we'll try to classify the same data with a different boosted model: xgboost. If you are running your code locally, you'll need to have xgboost installed. If you are using Colab, then you are ready to boost!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8J1UMBkmcrC7",
        "outputId": "d23a32a1-a915-46e9-8967-3357734e58db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load xgboost and fit the model\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xg_classifier = XGBClassifier(n_estimators=50, random_state=42)\n",
        "\n",
        "xg_classifier.fit(X_train,y_train)\n",
        "\n",
        "print('Validation Accuracy: Adaboost', xg_classifier.score(X_test, y_test))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: Adaboost 0.9833333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj2uuUEBcs8U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}